<!DOCTYPE html>
<html>
<head>
    <title>Data Mining & Machine Learning - Exam Revision</title>
    <meta charset="UTF-8">
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <h1>Data Mining & Machine Learning - Exam Revision</h1>
<div class="top-actions">
        <a class="home-btn" href="index.html" aria-label="Go to home">Home</a>
    </div>
    <h2>I. Data Anatomy and Attribute Types</h2>
    <h3>1. Dataset Structure</h3>
    <ul>
        <li><strong>Instances (Records):</strong> Single independent examples.</li>
        <li><strong>Attributes (Features):</strong> Describe each instance.</li>
        <li><strong>Class (Target Attribute):</strong> Attribute to predict.</li>
    </ul>

    <h3>2. Attribute Value Types</h3>
    <table border="1">
        <tr>
            <th>Type</th>
            <th>Characteristics</th>
            <th>Operations</th>
            <th>Examples</th>
        </tr>
        <tr>
            <td><strong>Nominal</strong> (Categorical)</td>
            <td>Distinct labels, no order or distance</td>
            <td>Equality tests</td>
            <td>Marital Status, Car Type</td>
        </tr>
        <tr>
            <td><strong>Ordinal</strong></td>
            <td>Ordered, no defined distance</td>
            <td>Ordering, comparison</td>
            <td>Service Rating, Grades</td>
        </tr>
        <tr>
            <td><strong>Interval</strong></td>
            <td>Ordered, equal units, no true zero</td>
            <td>Difference</td>
            <td>Temperature (F), Year</td>
        </tr>
        <tr>
            <td><strong>Ratio</strong></td>
            <td>Ordered, equal units, true zero</td>
            <td>All math operations</td>
            <td>Distance, Height, Age</td>
        </tr>
    </table>

    <h2>II. Data Preparation, Scaling, and Discretisation</h2>
    <h3>1. Data Quality and Missing Values</h3>
    <ul>
        <li>Data can be messy, incomplete, or incorrect.</li>
        <li><strong>Missing Values (NULL):</strong> May mean refusal, lack, or error.</li>
    </ul>

    <h3>2. Scaling and Normalisation</h3>
    <ul>
        <li><strong>Instance Normalisation:</strong> Normalize each row by total (e.g., word count).</li>
        <li><strong>Attribute Min-Max Normalisation:</strong> Scale values to [0,1] or [-1,1].<br>
            Formula: <code>(v(r, j) - min(j)) / (max(j) - min(j))</code>
        </li>
        <li><strong>Attribute Standardisation (z-score):</strong> Mean 0, std dev 1.<br>
            Formula: <code>z = (x - μ) / σ</code>
        </li>
    </ul>

    <h3>3. Discretisation (Binning)</h3>
    <ul>
        <li>Converts numeric to categorical attributes.</li>
        <li><strong>Equal Width Binning (EWB):</strong> Bins have equal width.</li>
        <li><strong>Equal Frequency Binning (EFB):</strong> Bins have equal number of data points.</li>
    </ul>

    <h2>III. Model Testing and Evaluation Setup</h2>
    <h3>1. Overfitting and Error Types</h3>
    <ul>
        <li><strong>Re-substitution Error:</strong> Error on training data (overly optimistic).</li>
        <li><strong>Overfitting:</strong> Model fits training data too well, poor generalisation.</li>
        <li><strong>Test Set:</strong> Must be independent from training data.</li>
    </ul>

    <h3>2. Data Splitting Methods</h3>
    <ul>
        <li><strong>Holdout Method:</strong> Split into training (2/3) and test (1/3) sets.</li>
        <li><strong>Validation Data:</strong> For parameter tuning; split into training, validation, and test sets.</li>
        <li><strong>K-fold Cross-Validation:</strong> Data split into k folds; each fold used as test once.<br>
            <ul>
                <li><strong>Stratification:</strong> Preserves class proportions.</li>
                <li><strong>Stratified 10-fold CV:</strong> Standard method.</li>
                <li><strong>Leave-one-out CV:</strong> Special case for small datasets.</li>
            </ul>
        </li>
    </ul>

    <h2>IV. Performance Measures</h2>
    <h3>1. Confusion Matrix (Binary Classification)</h3>
    <table border="1">
        <tr>
            <th></th>
            <th>Predicted Yes (Positive)</th>
            <th>Predicted No (Negative)</th>
        </tr>
        <tr>
            <th>Actually Yes (Positive)</th>
            <td>True Positive (TP)</td>
            <td>False Negative (FN)</td>
        </tr>
        <tr>
            <th>Actually No (Negative)</th>
            <td>False Positive (FP)</td>
            <td>True Negative (TN)</td>
        </tr>
    </table>

    <h3>2. Key Metrics and Formulas</h3>
    <ul>
        <li><strong>Accuracy:</strong> (TP + TN) / (TP + TN + FP + FN)</li>
        <li><strong>Error Rate:</strong> (FP + FN) / (TP + TN + FP + FN) = 1 - Accuracy</li>
        <li><strong>Recall (Sensitivity):</strong> TP / (TP + FN)</li>
        <li><strong>Precision:</strong> TP / (TP + FP)</li>
        <li><strong>Specificity:</strong> TN / (TN + FP)</li>
        <li><strong>F-measure:</strong> 2 × (Recall × Precision) / (Recall + Precision)</li>
    </ul>

    <h3>3. Graphical Evaluation</h3>
    <ul>
        <li><strong>ROC Curve:</strong> Plots True Positive Rate vs. False Positive Rate.</li>
        <li><strong>Area Under ROC Curve (AUC):</strong> Probability that a random positive is ranked above a random negative. Higher is better.</li>
    </ul>
</body>
</html>