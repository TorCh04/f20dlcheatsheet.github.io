<!DOCTYPE html>
<html>
<head>
  <title>Data Mining & Machine Learning Exam Revision Guide</title>
  <meta charset="UTF-8">
  <link rel="stylesheet" href="styles.css">
</head>
<body>
  <h1>Data Mining & Machine Learning Exam Revision Guide</h1>
    <div class="top-actions">
        <a class="home-btn" href="index.html" aria-label="Go to home">Home</a>
    </div>
  <h2>1. Perceptron and Linear Models</h2>
  <h3>1.1 Geometric Intuition & Hyperplanes</h3>
  <ul>
    <li>A <b>hyperplane</b> separates a D-dimensional space into two halves, defined by a weight vector <b>w</b> (orthogonal to the hyperplane) and bias <b>b</b>.</li>
    <li>Prediction: <code>ŷ = sign(wᵗx + b)</code></li>
    <li>Decision boundary is the set of points where <code>wᵗx + b = 0</code>.</li>
    <li>Bias shifts the decision boundary away from the origin.</li>
  </ul>

  <h3>1.2 Perceptron Algorithm</h3>
  <ul>
    <li>Online, error-driven learning: update weights only when an error is made.</li>
    <li>Update rule: <code>w_new = w_old + yx</code>, <code>b_new = b_old + y</code> (for misclassified example (x, y)).</li>
    <li>Converges if data is linearly separable (Perceptron Convergence Theorem).</li>
    <li>Margin: distance between hyperplane and nearest point; larger margin = faster convergence.</li>
  </ul>

  <h3>1.3 Worked Example: Perceptron Update</h3>
  <ul>
    <li>Given <code>x_T1 = [0,1,0,1]</code>, <code>y_T1 = 1</code>, initial <code>w = [0,0,0,0]</code>, <code>b = 0</code>:</li>
    <li>Activation <code>a = 0</code>, error made, update: <code>w = [0,1,0,1]</code>, <code>b = 1</code>.</li>
  </ul>

  <h2>2. Linear Models & Gradient Descent</h2>
  <h3>2.1 Objective Function & Regularisation</h3>
  <ul>
    <li>General form: <code>min_{w,b} L(w,b) = sum_n l(w,b;x_n,y_n) + λR(w,b)</code></li>
    <li><b>Loss function</b> (l): measures fit to data (e.g., squared loss, hinge loss, log loss).</li>
    <li><b>Regulariser</b> (R): penalises large weights to encourage simpler models (L2: <code>||w||²</code>, L1: <code>||w||₁</code>).</li>
  </ul>

  <h3>2.2 Gradient Descent Algorithm</h3>
  <ul>
    <li>Iteratively update parameters in the direction of negative gradient.</li>
    <li>Update: <code>w = w - η∇_w L</code>, <code>b = b - η∂L/∂b</code></li>
    <li>Variants: batch (whole dataset), stochastic (single example), mini-batch.</li>
    <li>Learning rate (η) controls step size; too small = slow, too large = divergence.</li>
  </ul>

  <h3>2.3 Linear Regression via Gradient Descent</h3>
  <ul>
    <li>Objective: minimise sum of squared errors (SSE): <code>sum_n (y_n - (wᵗx_n + b))²</code></li>
    <li>Gradient w.r.t. w: <code>-2 sum_n (y_n - (wᵗx_n + b)) x_n + λw</code></li>
    <li>Gradient w.r.t. b: <code>-2 sum_n (y_n - (wᵗx_n + b))</code></li>
    <li>Update rules as above.</li>
  </ul>

  <h3>2.4 Worked Example: Linear Regression Update</h3>
  <ul>
    <li>Given <code>x_T1 = [1,0,1,0,1]</code>, <code>Y_T1 = 1</code>, <code>w = [1,2,3,1,2]</code>, <code>η = 1</code>:</li>
    <li>Prediction: <code>6</code>, error: <code>-5</code>, update: <code>w = [-4,2,-2,1,-3]</code></li>
  </ul>

  <h2>3. Loss Functions</h2>
  <ul>
    <li><b>0-1 Loss:</b> <code>l(y,ŷ) = 1[yŷ ≤ 0]</code> (non-convex, non-smooth)</li>
    <li><b>Hinge Loss:</b> <code>max(0, 1 - yŷ)</code> (used in SVMs)</li>
    <li><b>Logistic Loss:</b> <code>log(1 + exp(-yŷ))</code> (used in logistic regression)</li>
    <li><b>Exponential Loss:</b> <code>exp(-yŷ)</code></li>
    <li><b>Squared Loss:</b> <code>(y - ŷ)²</code> (used in regression)</li>
    <li>Convex surrogate losses are used for efficient optimisation.</li>
  </ul>

  <h2>4. Regularisation</h2>
  <ul>
    <li>Encourages simpler models (smaller weights), reduces overfitting.</li>
    <li><b>L2 norm:</b> <code>||w||²</code> (smooth, convex)</li>
    <li><b>L1 norm:</b> <code>||w||₁</code> (sparse, convex, non-smooth)</li>
    <li>General objective: <code>min_{w,b} sum_n l(w,b;x_n,y_n) + λR(w,b)</code></li>
  </ul>

  <h2>5. Logistic Regression & Sigmoid Function</h2>
  <ul>
    <li>Sigmoid: <code>σ(x) = 1 / (1 + exp(-x))</code></li>
    <li>Probability estimate: <code>P(ŷ=1|x) = σ(wᵗx)</code></li>
    <li>Log-loss (cross-entropy): <code>-sum_n Y(x_n) log(ŷ(x_n)) + (1-Y(x_n)) log(1-ŷ(x_n))</code></li>
    <li>Gradient: <code>∇_w = -sum_n (Y(x_n) - ŷ(x_n)) x_n</code></li>
  </ul>

  <h2>6. Neural Networks</h2>
  <h3>6.1 Perceptron Recap</h3>
  <ul>
    <li>Single neuron: <code>a = w·x + b</code>, fires if <code>a > 0</code>.</li>
  </ul>
  <h3>6.2 Multi-Layer Perceptrons (MLP)</h3>
  <ul>
    <li>Stack multiple perceptrons in layers (input, hidden, output).</li>
    <li>Hidden layer applies non-linear activation (e.g., tanh, sigmoid, ReLU).</li>
    <li>Output: <code>ŷ = v·f(Wx)</code> (v: output weights, W: hidden weights, f: activation).</li>
    <li>Universal Approximation Theorem: 2-layer networks can approximate any continuous function.</li>
  </ul>
  <h3>6.3 Training Neural Networks: Backpropagation</h3>
  <ul>
    <li>Backpropagation = Gradient Descent + Chain Rule.</li>
    <li>Gradients for output weights: <code>∇_v = -sum_n e_n h_n</code> (e: error, h: hidden activations).</li>
    <li>Gradients for hidden weights: <code>∇_{w_i} = -e v_i f'(w_i·x) x</code></li>
    <li>Random initialisation of weights is important.</li>
    <li>Hyperparameters: number of hidden units/layers, learning rate, stopping criterion.</li>
  </ul>

  <h2>7. Convolutional Neural Networks (CNN)</h2>
  <ul>
    <li>Specialised for 2D data (e.g., images).</li>
    <li><b>Local receptive fields:</b> Each neuron connects to a small region of input.</li>
    <li><b>Shared weights:</b> Same filter applied across input (parameter sharing).</li>
    <li><b>Pooling layers:</b> Downsample feature maps (e.g., max-pooling).</li>
    <li>Typical structure: Convolution → Pooling → Dense (fully connected) → Output.</li>
  </ul>

  <h2>8. Decision Trees</h2>
  <h3>8.1 Structure & Training</h3>
  <ul>
    <li>Hierarchical, divide-and-conquer model.</li>
    <li>Internal nodes: feature tests; leaves: class labels.</li>
    <li>Recursive splitting based on best feature (greedy/myopic splitting).</li>
    <li>Stop splitting when nodes are pure or no features remain.</li>
    <li>Prefer simpler (shallower) trees (Occam’s razor).</li>
  </ul>
  <h3>8.2 Impurity Measures</h3>
  <ul>
    <li><b>Gini Index:</b> <code>G = 1 - sum_k p_k²</code> (p_k: proportion of class k in node).</li>
    <li>Lower Gini = purer node.</li>
    <li>Entropy/information gain also used for splitting.</li>
  </ul>
  <h3>8.3 Overfitting & Generalisation</h3>
  <ul>
    <li>Perfect fit on training data does not guarantee good generalisation.</li>
    <li>Overfitting: low training error, high test error.</li>
    <li>Prevent overfitting by restricting splits, pruning, or using ensembles (random forests).</li>
  </ul>

  <h2>9. Model Evaluation & Overfitting</h2>
  <ul>
    <li>Training error is not sufficient; must evaluate on separate test/validation set.</li>
    <li><b>Overfitting:</b> <code>error_train(h) < error_true(h)</code></li>
    <li>Common error metrics: MAE, MSE, RMSE, Maximum Error.</li>
    <li>Generalisation is the true test of model quality.</li>
  </ul>

  <h2>10. Worked Examples</h2>
  <h3>10.1 Customer Transactions (Linear Regression)</h3>
  <ul>
    <li>Features: binary (yes=1, no=0), output: buys=1, cancels=0.</li>
    <li>Learn weights to minimise SSE.</li>
    <li>Interpret weights: positive increases prediction, negative decreases.</li>
  </ul>
  <h3>10.2 Read Emails (Logistic Regression)</h3>
  <ul>
    <li>Features: thread (old/new), length (short/long), where (work/home).</li>
    <li>Output: skip=0, read=1.</li>
    <li>Learned function: <code>σ(w₀ + w₁·thread + w₂·length + w₃·where)</code></li>
    <li>Prediction: if output ≥ 0.5, predict read; else skip.</li>
  </ul>

  <h2>11. Inductive Bias & Model Comparison</h2>
  <ul>
    <li>Linear/logistic regression: good for additive, thresholded concepts.</li>
    <li>Decision trees: good for conditional logic.</li>
    <li>Neural networks: can represent complex, non-linear functions.</li>
    <li>Smaller weights/simpler models preferred for better generalisation.</li>
  </ul>

  <h2>12. Summary Tables</h2>
  <h3>12.1 Decision Tree Algorithms</h3>
  <table border="1">
    <tr><th>Algorithm</th><th>Purpose</th><th>Main Steps</th></tr>
    <tr><td>Training</td><td>Build the tree</td><td>Recursively split data by best feature until pure or no features remain</td></tr>
    <tr><td>Inference</td><td>Classify input</td><td>Traverse tree from root to leaf using input’s feature values</td></tr>
  </table>

  <h3>12.2 Error Metrics</h3>
  <table border="1">
    <tr><th>Metric</th><th>Formula</th><th>Interpretation</th></tr>
    <tr><td>MAE</td><td><code>1/n sum |Y - Ŷ|</code></td><td>Average absolute error</td></tr>
    <tr><td>MSE</td><td><code>1/n sum (Y - Ŷ)²</code></td><td>Average squared error</td></tr>
    <tr><td>RMSE</td><td><code>sqrt(MSE)</code></td><td>Root mean squared error</td></tr>
    <tr><td>Max Error</td><td><code>max |Y - Ŷ|</code></td><td>Largest absolute error</td></tr>
  </table>

  <h2>13. Key Takeaways</h2>
  <ul>
    <li>Understand the strengths and limitations of each model (perceptron, linear models, neural networks, decision trees, CNNs).</li>
    <li>Know how to derive and apply update rules for gradient descent and perceptron.</li>
    <li>Be able to interpret weights and model outputs.</li>
    <li>Always evaluate models on unseen data to assess generalisation.</li>
    <li>Prefer simpler models when possible to avoid overfitting.</li>
  </ul>

</body>
</html>